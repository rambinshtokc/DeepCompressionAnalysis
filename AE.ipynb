{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Dataset\n",
    "def load_data(img_dir):\n",
    "    x_data = []\n",
    "    image_paths = [os.path.join(img_dir, w) for w in os.listdir(img_dir) if w.endswith(\".png\")]\n",
    "    for image_path in image_paths:\n",
    "        img = Image.open(image_path).convert('L')  # Load image in grayscale\n",
    "        img = img.resize((128, 128))  # Ensure image is 128x128\n",
    "        x_data.append(np.array(img))\n",
    "    return np.array(x_data)\n",
    "\n",
    "# Prepare Data\n",
    "data = load_data(\"/home/thumbnails128x128\")\n",
    "data = data.astype('float32') / 255.0\n",
    "\n",
    "# Add channel dimension\n",
    "data = data[..., np.newaxis]\n",
    "\n",
    "# Convert to Tensors and permute to match the expected shape [batch_size, channels, height, width]\n",
    "data_tensor = torch.tensor(data).float().permute(0, 3, 1, 2).to(device)\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Calculate the sizes of each split\n",
    "total_size = len(data_tensor)\n",
    "train_size = int(total_size * train_ratio)\n",
    "val_size = int(total_size * val_ratio)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Shuffle the dataset\n",
    "indices = torch.randperm(total_size).tolist()\n",
    "\n",
    "# Split indices for each dataset\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "# Create TensorDataset from shuffled data\n",
    "train_dataset = TensorDataset(data_tensor[train_indices], data_tensor[train_indices])\n",
    "val_dataset = TensorDataset(data_tensor[val_indices], data_tensor[val_indices])\n",
    "test_dataset = TensorDataset(data_tensor[test_indices], data_tensor[test_indices])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Print the sizes of each dataset\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the AutoEncoder Model\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_autoencoder(train_loader, val_loader, lambda_1=None, lambda_2=None, model_name=None):\n",
    "    autoencoder = ConvAutoEncoder().to(device)  # Reinitialize the model for each regularization method\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Use weight_decay parameter for L2 regularization (if lambda_2 is provided)\n",
    "    optimizer_params = {'lr': 0.001}\n",
    "    if lambda_2 is not None:\n",
    "        optimizer_params['weight_decay'] = lambda_2\n",
    "\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), **optimizer_params)\n",
    "\n",
    "    num_epochs = 200\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        autoencoder.train()\n",
    "        epoch_train_loss = 0\n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "            for imgs, _ in train_loader:\n",
    "                imgs = imgs.to(device)  # Move data to device\n",
    "                outputs = autoencoder(imgs)\n",
    "                loss = criterion(outputs, imgs)\n",
    "                \n",
    "                # Add L1 regularization manually if selected\n",
    "                if lambda_1 is not None:\n",
    "                    l1_norm = sum(p.abs().sum() for p in autoencoder.parameters())\n",
    "                    loss += lambda_1 * l1_norm\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_train_loss += loss.item() * imgs.size(0)\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update()\n",
    "\n",
    "        avg_train_loss = epoch_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Average Loss: {avg_train_loss:.5f}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        autoencoder.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in val_loader:\n",
    "                imgs = imgs.to(device)  # Move data to device\n",
    "                outputs = autoencoder(imgs)\n",
    "                loss = criterion(outputs, imgs)\n",
    "                epoch_val_loss += loss.item() * imgs.size(0)\n",
    "        \n",
    "        avg_val_loss = epoch_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Average Loss: {avg_val_loss:.5f}\")\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = autoencoder.state_dict()\n",
    "\n",
    "    # Save the best model for this regularization setting\n",
    "    if best_model_state is not None:\n",
    "        torch.save(best_model_state, f'./autoencoder_best_{model_name}.pth')\n",
    "        print(f\"Best model for {model_name} saved with val loss {best_val_loss:.5f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def plot_losses(losses_dict):\n",
    "\n",
    "    # Training Loss Plot\n",
    "    #plt.subplot(2, 1, 1)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for label, losses in losses_dict['train'].items():\n",
    "        plt.plot(losses, label=label)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss Comparison with Different Regularization Settings')\n",
    "    plt.legend(loc='upper right')  # Place legend in the upper-right corner\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Validation Loss Plot\n",
    "    #plt.subplot(2, 1, 2)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for label, losses in losses_dict['val'].items():\n",
    "        plt.plot(losses, label=label)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.title('Validation Loss Comparison with Different Regularization Settings')\n",
    "    plt.legend(loc='upper right')  # Place legend in the upper-right corner\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model with different Regularization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lambda_1 = 1e-5\n",
    "lambda_2 = 1e-5\n",
    "\n",
    "train_losses = {}\n",
    "val_losses = {}\n",
    "\n",
    "# Train and save models with different regularization methods\n",
    "train_losses['No Reg'], val_losses['No Reg'] = train_autoencoder(\n",
    "    train_loader, val_loader, model_name='no_reg'\n",
    ")\n",
    "train_losses['L2'], val_losses['L2'] = train_autoencoder(\n",
    "    train_loader, val_loader, lambda_2=lambda_2, model_name='l2_reg'\n",
    ")\n",
    "train_losses['L1'], val_losses['L1'] = train_autoencoder(\n",
    "    train_loader, val_loader, lambda_1=lambda_1, model_name='l1_reg'\n",
    ")\n",
    "train_losses['L1 + L2'], val_losses['L1 + L2'] = train_autoencoder(\n",
    "    train_loader, val_loader, lambda_1=lambda_1, lambda_2=lambda_2, model_name='l1_l2_reg'\n",
    ")\n",
    "\n",
    "# Plot all losses\n",
    "plot_losses({\n",
    "    'train': train_losses,\n",
    "    'val': val_losses\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Evaluation Matrices and plot an example of reconstructed images for diffrent regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def calculate_mse(image1, image2):\n",
    "    return np.mean((image1 - image2) ** 2)\n",
    "\n",
    "def calculate_psnr(mse, max_pixel=1.0):\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 10 * np.log10(max_pixel ** 2 / mse)\n",
    "\n",
    "def plot_single_image_reconstructions(image_index, model_paths, titles, test_loader):\n",
    "    # Get a batch of test images\n",
    "    images, _ = next(iter(test_loader))  # Get a batch from the test loader\n",
    "    images = images.to(device)  # Move to device\n",
    "    \n",
    "    # Select the image to be reconstructed\n",
    "    original_img = images[image_index].cpu().numpy()\n",
    "\n",
    "    # Initialize the plot\n",
    "    fig, axes = plt.subplots(1, len(model_paths) + 1, figsize=(20, 5))\n",
    "    \n",
    "    # Plot the original image\n",
    "    axes[0].imshow(original_img[0], cmap='gray')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Original Image')\n",
    "    \n",
    "    for i, (model_path, title) in enumerate(zip(model_paths, titles), start=1):\n",
    "        # Load and evaluate the model\n",
    "        model = ConvAutoEncoder().to(device)\n",
    "        model.load_state_dict(torch.load(f'./{model_path}.pth'))\n",
    "        model.eval()\n",
    "        \n",
    "        # Reconstruct the image\n",
    "        with torch.no_grad():\n",
    "            img_tensor = images[image_index].unsqueeze(0).to(device)\n",
    "            reconstructed_img = model(img_tensor).cpu().numpy()[0]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse_value = calculate_mse(original_img, reconstructed_img)\n",
    "        psnr_value = calculate_psnr(mse_value)\n",
    "        ssim_value = ssim(original_img[0], reconstructed_img[0], data_range=1.0)\n",
    "        \n",
    "        # Plot reconstructed image\n",
    "        axes[i].imshow(reconstructed_img[0], cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(title)\n",
    "        \n",
    "        # Add MSE, PSNR, and SSIM text without additional gap\n",
    "        axes[i].text(0.5, -0.03, \n",
    "                     f'MSE: {mse_value:.5f}\\nPSNR: {psnr_value:.2f} dB\\nSSIM: {ssim_value:.4f}', \n",
    "                     ha='center', va='top', transform=axes[i].transAxes, fontsize=10, bbox=dict(facecolor='white', alpha=0.75,edgecolor='none'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "model_paths = [\n",
    "    'autoencoder_best_no_reg',\n",
    "    'autoencoder_best_l1_reg',\n",
    "    'autoencoder_best_l2_reg',\n",
    "    'autoencoder_best_l1_l2_reg'\n",
    "]\n",
    "titles = [\n",
    "    'No Regularization',\n",
    "    'L1 Regularization',\n",
    "    'L2 Regularization',\n",
    "    'L1 + L2 Regularization'\n",
    "]\n",
    "\n",
    "# Plot for a specific image index, e.g., 0\n",
    "plot_single_image_reconstructions(0, model_paths, titles, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Histograms of Evaluation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# List of model paths and titles for plots\n",
    "model_paths = [\n",
    "    'autoencoder_best_no_reg',\n",
    "    'autoencoder_best_l1_reg',\n",
    "    'autoencoder_best_l2_reg',\n",
    "    'autoencoder_best_l1_l2_reg'\n",
    "]\n",
    "titles = [\n",
    "    'No Regularization',\n",
    "    'L1 Regularization',\n",
    "    'L2 Regularization',\n",
    "    'L1 + L2 Regularization'\n",
    "]\n",
    "\n",
    "#Function to plot histograms with mean, median, and std dev lines\n",
    "def plot_histogram_with_stats(ax, data, color, xlabel, ylabel):\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    std = np.std(data)\n",
    "\n",
    "    ax.hist(data, bins=30, color=color, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(mean, color='blue', linestyle='dashed', linewidth=1, label=f'Mean: {mean:.5f}')\n",
    "    ax.axvline(median, color='red', linestyle='dashed', linewidth=1, label=f'Median: {median:.5f}')\n",
    "    ax.axvline(mean + std, color='green', linestyle='dashed', linewidth=1, label=f'Std Dev: {std:.5f}')\n",
    "    ax.axvline(mean - std, color='green', linestyle='dashed', linewidth=1)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(original_images, reconstructed_images):\n",
    "    mse_list = []\n",
    "    ssim_list = []\n",
    "    psnr_list = []\n",
    "    \n",
    "    for i in range(original_images.shape[0]):  # Assuming batch size is first dimension\n",
    "        original_img = original_images[i].squeeze()  # Remove channel dimension\n",
    "        reconstructed_img = reconstructed_images[i].squeeze()  # Remove channel dimension\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse = mean_squared_error(original_img.flatten(), reconstructed_img.flatten())\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "        # Calculate SSIM\n",
    "        ssim_value = ssim(original_img, reconstructed_img, data_range=1.0)  # Adjust data_range as needed\n",
    "        ssim_list.append(ssim_value)\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_value = psnr(original_img, reconstructed_img, data_range=1.0)  # Adjust data_range as needed\n",
    "        psnr_list.append(psnr_value)\n",
    "    \n",
    "    return mse_list, ssim_list, psnr_list\n",
    "\n",
    "# Create a figure with subplots for each model\n",
    "fig, axes = plt.subplots(3, len(model_paths), figsize=(18, 12))\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "for idx, (model_path, title) in enumerate(zip(model_paths, titles)):\n",
    "    # Initialize lists to store metrics for this model\n",
    "    mse_list = []\n",
    "    ssim_list = []\n",
    "    psnr_list = []\n",
    "\n",
    "    # Load and evaluate the model\n",
    "    model = ConvAutoEncoder().to(device)\n",
    "    model.load_state_dict(torch.load(f'./{model_path}.pth'))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            images, _ = batch\n",
    "            images = images.to(device)  # Images should already be in shape (batch_size, channels, height, width)\n",
    "            \n",
    "            # Reconstruct images\n",
    "            reconstructed_images = model(images)  # Adjust according to your ConvAutoEncoder output\n",
    "            \n",
    "            # Convert images and reconstructed images to numpy arrays\n",
    "            original_images = images.cpu().numpy()  # Shape should be (batch_size, 1, height, width)\n",
    "            reconstructed_images = reconstructed_images.cpu().numpy()  # Shape should be (batch_size, 1, height, width)\n",
    "\n",
    "            # Calculate metrics\n",
    "            mse, ssim_values, psnr_values = calculate_metrics(original_images, reconstructed_images)\n",
    "            mse_list.extend(mse)\n",
    "            ssim_list.extend(ssim_values)\n",
    "            psnr_list.extend(psnr_values)\n",
    "\n",
    "    # Ensure all lists have the same length\n",
    "    min_length = min(len(mse_list), len(ssim_list), len(psnr_list))\n",
    "    mse_list = mse_list[:min_length]\n",
    "    ssim_list = ssim_list[:min_length]\n",
    "    psnr_list = psnr_list[:min_length]\n",
    "\n",
    "    # Plot histograms for MSE, SSIM, and PSNR in respective rows\n",
    "    ax_mse = axes[0, idx]\n",
    "    ax_ssim = axes[1, idx]\n",
    "    ax_psnr = axes[2, idx]\n",
    "\n",
    "    # MSE Plot\n",
    "    plot_histogram_with_stats(ax_mse, mse_list, 'blue', 'MSE', 'Frequency')\n",
    "    ax_mse.set_title(f'{title} - MSE')\n",
    "\n",
    "    # SSIM Plot\n",
    "    plot_histogram_with_stats(ax_ssim, ssim_list, 'green', 'SSIM', 'Frequency')\n",
    "    ax_ssim.set_title(f'{title} - SSIM')\n",
    "\n",
    "    # PSNR Plot\n",
    "    plot_histogram_with_stats(ax_psnr, psnr_list, 'red', 'PSNR', 'Frequency')\n",
    "    ax_psnr.set_title(f'{title} - PSNR')\n",
    "\n",
    "plt.show()  # Display the combined plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0, std=0.1):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to the input image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The input image (numpy array or PyTorch tensor).\n",
    "    - mean: Mean of the Gaussian noise.\n",
    "    - std: Standard deviation of the Gaussian noise.\n",
    "    \n",
    "    Returns:\n",
    "    - Noisy image.\n",
    "    \"\"\"\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.cpu().numpy()  # Convert to numpy array if it's a tensor\n",
    "    \n",
    "    noise = np.random.normal(mean, std, image.shape).astype(np.float32)\n",
    "    noisy_image = image + noise\n",
    "    \n",
    "    # Clip the values to be in the valid range (0-1 for normalized images)\n",
    "    noisy_image = np.clip(noisy_image, 0, 1)\n",
    "    \n",
    "    if isinstance(image, torch.Tensor):\n",
    "        noisy_image = torch.tensor(noisy_image, dtype=torch.float32)  # Convert back to tensor if needed\n",
    "    \n",
    "    return noisy_image\n",
    "\n",
    "class NoisyDataset(TensorDataset):\n",
    "    def __init__(self, tensors, noise_mean=0, noise_std=0.1):\n",
    "        super(NoisyDataset, self).__init__(*tensors)\n",
    "        self.noise_mean = noise_mean\n",
    "        self.noise_std = noise_std\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        original_image, target_image = super(NoisyDataset, self).__getitem__(index)\n",
    "        noisy_image = add_gaussian_noise(original_image, mean=self.noise_mean, std=self.noise_std)\n",
    "        return noisy_image, target_image\n",
    "\n",
    "# Define noise parameters\n",
    "noise_mean = 0\n",
    "noise_std = 0.1\n",
    "\n",
    "del train_loader, val_loader, test_loader\n",
    "del train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Create noisy datasets\n",
    "train_dataset_noisy = NoisyDataset((data_tensor[train_indices], data_tensor[train_indices]), noise_mean=noise_mean, noise_std=noise_std)\n",
    "val_dataset_noisy = NoisyDataset((data_tensor[val_indices], data_tensor[val_indices]), noise_mean=noise_mean, noise_std=noise_std)\n",
    "test_dataset_noisy = NoisyDataset((data_tensor[test_indices], data_tensor[test_indices]), noise_mean=noise_mean, noise_std=noise_std)\n",
    "\n",
    "# Create data loaders for noisy data\n",
    "train_loader_noisy = DataLoader(train_dataset_noisy, batch_size=128, shuffle=True)\n",
    "val_loader_noisy = DataLoader(val_dataset_noisy, batch_size=128, shuffle=False)\n",
    "test_loader_noisy = DataLoader(test_dataset_noisy, batch_size=128, shuffle=False)\n",
    "\n",
    "# Print the sizes of each noisy dataset\n",
    "print(f\"Noisy Training set size: {len(train_dataset_noisy)}\")\n",
    "print(f\"Noisy Validation set size: {len(val_dataset_noisy)}\")\n",
    "print(f\"Noisy Test set size: {len(test_dataset_noisy)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model with noisy data for different Regularization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "lambda_1 = 1e-5\n",
    "lambda_2 = 1e-5\n",
    "\n",
    "train_losses = {}\n",
    "val_losses = {}\n",
    "\n",
    "# Train and save models with different regularization methods\n",
    "train_losses['No Reg'], val_losses['No Reg'] = train_autoencoder(\n",
    "    train_loader_noisy, val_loader_noisy, model_name='no_reg_noisy'\n",
    ")\n",
    "train_losses['L2'], val_losses['L2'] = train_autoencoder(\n",
    "    train_loader_noisy, val_loader_noisy, lambda_2=lambda_2, model_name='l2_reg_noisy'\n",
    ")\n",
    "train_losses['L1'], val_losses['L1'] = train_autoencoder(\n",
    "    train_loader_noisy, val_loader_noisy, lambda_1=lambda_1, model_name='l1_reg_noisy'\n",
    ")\n",
    "train_losses['L1 + L2'], val_losses['L1 + L2'] = train_autoencoder(\n",
    "    train_loader_noisy, val_loader_noisy, lambda_1=lambda_1, lambda_2=lambda_2, model_name='l1_l2_reg_noisy'\n",
    ")\n",
    "\n",
    "# Plot all losses\n",
    "plot_losses({\n",
    "    'train': train_losses,\n",
    "    'val': val_losses\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting an example of reconstructed noisy images for diffrent regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of model paths and titles for plots\n",
    "model_paths = [\n",
    "    'autoencoder_best_no_reg_noisy',\n",
    "    'autoencoder_best_l1_reg_noisy',\n",
    "    'autoencoder_best_l2_reg_noisy',\n",
    "    'autoencoder_best_l1_l2_reg_noisy'\n",
    "]\n",
    "titles = [\n",
    "    'No Regularization',\n",
    "    'L1 Regularization',\n",
    "    'L2 Regularization',\n",
    "    'L1 + L2 Regularization'\n",
    "]\n",
    "\n",
    "# Plot for a specific image index, e.g., 0\n",
    "plot_single_image_reconstructions(0, model_paths, titles, test_loader_noisy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Histograms of Evaluation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# List of model paths and titles for plots\n",
    "model_paths = [\n",
    "    'autoencoder_best_no_reg',\n",
    "    'autoencoder_best_l1_reg_noisy',\n",
    "    'autoencoder_best_l2_reg_noisy',\n",
    "    'autoencoder_best_l1_l2_reg_noisy'\n",
    "]\n",
    "titles = [\n",
    "    'No Regularization',\n",
    "    'L1 Regularization',\n",
    "    'L2 Regularization',\n",
    "    'L1 + L2 Regularization'\n",
    "]\n",
    "\n",
    "# Create a figure with subplots for each model\n",
    "fig, axes = plt.subplots(3, len(model_paths), figsize=(18, 12))\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "for idx, (model_path, title) in enumerate(zip(model_paths, titles)):\n",
    "    # Initialize lists to store metrics for this model\n",
    "    mse_list = []\n",
    "    ssim_list = []\n",
    "    psnr_list = []\n",
    "\n",
    "    # Load and evaluate the model\n",
    "    model = ConvAutoEncoder().to(device)\n",
    "    model.load_state_dict(torch.load(f'./{model_path}.pth'))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader_noisy):\n",
    "            images, _ = batch\n",
    "            images = images.to(device)  # Images should already be in shape (batch_size, channels, height, width)\n",
    "            \n",
    "            # Reconstruct images\n",
    "            reconstructed_images = model(images)  # Adjust according to your ConvAutoEncoder output\n",
    "            \n",
    "            # Convert images and reconstructed images to numpy arrays\n",
    "            original_images = images.cpu().numpy()  # Shape should be (batch_size, 1, height, width)\n",
    "            reconstructed_images = reconstructed_images.cpu().numpy()  # Shape should be (batch_size, 1, height, width)\n",
    "\n",
    "            # Calculate metrics\n",
    "            mse, ssim_values, psnr_values = calculate_metrics(original_images, reconstructed_images)\n",
    "            mse_list.extend(mse)\n",
    "            ssim_list.extend(ssim_values)\n",
    "            psnr_list.extend(psnr_values)\n",
    "\n",
    "    # Ensure all lists have the same length\n",
    "    min_length = min(len(mse_list), len(ssim_list), len(psnr_list))\n",
    "    mse_list = mse_list[:min_length]\n",
    "    ssim_list = ssim_list[:min_length]\n",
    "    psnr_list = psnr_list[:min_length]\n",
    "\n",
    "    # Plot histograms for MSE, SSIM, and PSNR in respective rows\n",
    "    ax_mse = axes[0, idx]\n",
    "    ax_ssim = axes[1, idx]\n",
    "    ax_psnr = axes[2, idx]\n",
    "\n",
    "    # MSE Plot\n",
    "    plot_histogram_with_stats(ax_mse, mse_list, 'blue', 'MSE', 'Frequency')\n",
    "    ax_mse.set_title(f'{title} - MSE')\n",
    "\n",
    "    # SSIM Plot\n",
    "    plot_histogram_with_stats(ax_ssim, ssim_list, 'green', 'SSIM', 'Frequency')\n",
    "    ax_ssim.set_title(f'{title} - SSIM')\n",
    "\n",
    "    # PSNR Plot\n",
    "    plot_histogram_with_stats(ax_psnr, psnr_list, 'red', 'PSNR', 'Frequency')\n",
    "    ax_psnr.set_title(f'{title} - PSNR')\n",
    "\n",
    "plt.show()  # Display the combined plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
